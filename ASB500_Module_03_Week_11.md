# Week 11: Word frequency based analyses


shares much with classical content analysis

### Overview

- computers do the coding.
- people build the dictionary in the first place. But once you have a dictionary that assigns words to themes, the computer does most of the rest.
- less time intensive
- increase reliability over human coders
- reliability does not guarantee validity

### deductive

1. define constructs
2. evaluate construct validity against literature
3. develop exhaustive list of key words for each construct
4. validate word lists with expert raters
5. apply dictionary to text

### inductive

1. identify words OR identify themes
2. group words into themes OR list keywords for each theme
3. establish reliability
4. revise dictionary
5. apply dictionary to text

### example

inclusion criteria are actually all the words that should be counted as an expression of a theme.

1. took the messy, free-flowing text form the comment cards, and entered it into a text analysis package
2. built a stop list of words to ignore
3. tabulated word frequencies to find the most common words.
4. classified these words into different themes and starting looking for synonyms or related terms that might also be indicators of the themes.
5. continued this process until they had as complete a list as possible of the words that reflected all the themes in their coding scheme.

### types of content dictionaries

#### all purpose (deductive)

- general inquirer
- dictionaries are meant to assess constructs that occur in a wide range of texts

#### specialized (deductive)

- contain words and phrases indicative of specific constructs derived from theory

#### individual (deductive or inductive)

- created for a single study

### marking of text is automated

1. computer reads the files and ignore a stop list
2. cuts off suffixes to create word stems
3. uses algorithm to assign each stem to a particular category
4. usually 80-90% of text is tagged; human coders review and code untagged terms

### example: general inquirer

- http://wjh.harvard.edu/~inquirer/
- One of the best known systems for content dictionary approaches is the General Inquirer, which was developed by Philip Stone and his colleagues at Harvard in the 1960s




# live lecture


- advantages to word count;
- quick easy, straight forward, clear, what terms of topics pop up
- codes are not needed
- auto code
- save time
- defensible in context of low language competence
- similar to univariate analysis before multivariate analysis for example
- can execute in vivo analysis and generate word clusters
- anova / t test / chi square
- how to operationalize how word is used? did people use the word, yes or no?


t-test or anova / a list of word frequencies is not publishable, unless:


1. structural qualitative or contextual comparison; key word in context analysis
2.
3.


- look at example from video lecture; comparison of Mexican preschools with two different types of curriculum
- take a word cluster/invivo code based on words,
- in low achieving preschool, using word, "aver" is very directive
- in high achieving, same word is used in different way,

..


Content dictionaries


natural language processing
