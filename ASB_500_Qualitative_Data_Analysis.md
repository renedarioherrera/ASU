# Module 1: Introduction and Building Blocks


1. [Introduction & Identifying themes](ASB500_Module_01_Week_01.md)
2. [Describing themes](ASB500_Module_01_Week_02.md)
3. [Building and Applying Codebooks](ASB500_Module_01_Week_03.md)
4. [Making Comparisons](ASB500_Module_01_Week_04.md)
5. [Building & Testing Models](ASB500_Module_01_Week_05.md)
6. Workshop on Application to real projects


# Module 2: Inductive Code-Based Approaches


1. [Schema Analysis](ASB500_Module_02_Week_07.md)
2. [Grounded Theory](ASB500_Module_02_Week_08.md)


# Module 3: Deductive Code-Based Approaches


1. [Classical Content Analysis](ASB500_Module_03_Week_09.md)
2. Workshop on Application to real projects


# Module 4: Word-Based Analyses


1. Text
2. Content dictionaries
3. [Semantic Network Analysis](ASB500_Module_04_Week_13.md)


# Live Class 20 October 2020


- last week was grounded theory; and still need to review the videos
- this week, classical content analysis;


## classical content analysis


- confirmatory
- the most extreme of text analysis approach in terms of orthodox implementation
- may be uncomfortable with people doing exploratory research
- goals of deductive/confirmatory text analysis are to test hypotheses or strengthen already existing models
- research must be within theory making space in already existing literature
- have some sense about key concepts and
- research question that posits relationship between concepts
- testing hypotheses
- asking question of comparison
- suitable approach for comparison, testing hypotheses
- understand terrain of exploratory and confirmatory; therefore you are able better understand which methods are most appropriate


with content analysis:


- suitable for cookie cutter approach; i.e. deductive coding
- ..
- with regard to transparency and scholarship it is important to share codes
- coding segments -> coding itself -> ..


segmentation:


- with transcripts or textual data;
- why do we need to segment data? word, sentence, paragraph
- to segment is to delineate unit
- yes, literature and theory can guide towards meaning,
- how do different types of data need to be segmented
- for example, segment focus group data by speaker; although problematic because may not be meaningful segmentation in context
- online survey and text box? depends on the question
- field notes? in time units,
- unstructured interview? by sentence? justifiable to talk about concept at level of interview
- line by line coding
- in vivo


grounded theory: does not support, structured valid and reliable comparisons within cross groups, instead supports ..


for example, policy is heavily structured:


codebook: maximum of up to 60 codes


in content comparison, why important for interrelate reliability:


- validation
- establish reliability
- do different people look at the codes and apply them in the same way
- fidelity
- coders must have similar understanding of the context, question, hypotheses, insider knowledge,


thought experiment, direct comparisons between groups:


- we are studying high income and low income, what is poverty?
- high income says poverty is "low social status"
- low income says poverty is "managing bureaucracy of poverty"
- it's possible that you will find non-meaningful comparison because codes aren't well defined leading to a giant mess because neither group is talking about the same thing
-
