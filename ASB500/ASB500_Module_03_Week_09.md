# Week 9: Classical Content Analysis


1. text as proxy for experience
2. free flowing text
3. analysis of: codes
4. confirmatory
5. content analysis & content dictionaries

- begins with theory,
- generates a set of specific, testable hypotheses,
- and test those hypotheses against the data

### Typical process of content analysis

- conceptualization to operationalization

#### content analysis begins with (ideal workflow)

- a theoretical rational derived from the literature or the investigator’s previous work.
- first task is to identify the important constructs involved in that theory
- develop ways to measure those constructs in text.

### sampling

- Sampling in content analysis is a two-step process.
- first step is the identification of the corpus of texts. If a small number of texts is collected (e.g., 40 life histories), then all can be analyzed. When hundreds or even thousands of texts are involved, a representative sample of records is required.
- In that case, the standard in classical content analysis is to draw a probability sample to represent the larger corpus of text to which you want to generalize.

#### sampling segmenting

- designed to identify the basic, nonoverlapping units of analysis within the texts.
- units may be the entire texts (books, interviews, responses to an open-ended survey question) or segments (words, word-senses, sentences, themes, paragraphs).
- Where the object is to compare across texts—to see whether or not certain themes occur—the whole text (representing an informant or an organization) is the appropriate unit of analysis.
- When the object is to compare the number of times a theme occurs across a set of texts, then a “context unit”—a chunk of text that reflects a theme—is likely to be the appropriate unit of analysis.

### Coding

- codes are typically developed from definitions given in the literature.
- In exploratory content analysis, inductive coding (open coding in grounded theory terms) is appropriate
- after an initial period of scrutinizing key resources (academic publications, the dataset itself, or both), researchers must make some tough decisions to define each code:
- What are the inclusion and exclusion criteria for this code?
- Is a particular instance of meaning “in” or “out”?
- What values can the code take?

#### steps

1. sample
2. pretest coding scheme
3. assign to two independent coders
4. measure reliability (reliability must be assessed for every code)
5. test for differences

### Sampling

- sampling frame
- systematic random sample

#### simple random sample

- A simple random sample is where you have a list of cases and you use a computer or random number table to pick a probability sample.
- There’s an important sampling problem here. A lot of researchers who do content analyses with periodicals avoid simple random samples, because there’s a high possibility that you could miss an entire issue or volume just by random sampling error.

#### systematic random sample

- Creating a systematic sample is rather easy. The researcher must first decide how many people out of the total population to include in the sample, keeping in mind that the larger the sample size, the more accurate, valid, and applicable the results will be. Then, the researcher will decide what the interval for sampling is, which will be the standard distance between each sampled element. This should be decided by dividing the total population by the desired sample size. In the example given above, the sampling interval is 10 because it is the result of dividing 10,000 (the total population) by 1,000 (the desired sample size). Finally, the researcher chooses an element from the list that falls below the interval, which in this case would be one of the first 10 elements within the sample, and then proceeds to select every tenth element.



## Live Session


- confirmatory
- the most extreme of text analysis approach in terms of orthodox implementation
- may be uncomfortable with people doing exploratory research
- goals of deductive/confirmatory text analysis are to test hypotheses or strengthen already existing models
- research must be within theory making space in already existing literature
- have some sense about key concepts and
- research question that posits relationship between concepts
- testing hypotheses
- asking question of comparison
- suitable approach for comparison, testing hypotheses
- understand terrain of exploratory and confirmatory; therefore you are able better understand which methods are most appropriate


with content analysis:


- suitable for cookie cutter approach; i.e. deductive coding
- ..
- with regard to transparency and scholarship it is important to share codes
- coding segments -> coding itself -> ..


segmentation:


- with transcripts or textual data;
- why do we need to segment data? word, sentence, paragraph
- to segment is to delineate unit
- yes, literature and theory can guide towards meaning,
- how do different types of data need to be segmented
- for example, segment focus group data by speaker; although problematic because may not be meaningful segmentation in context
- online survey and text box? depends on the question
- field notes? in time units,
- unstructured interview? by sentence? justifiable to talk about concept at level of interview
- line by line coding
- in vivo


grounded theory: does not support, structured valid and reliable comparisons within cross groups, instead supports ..


for example, policy is heavily structured:


codebook: maximum of up to 60 codes


in content comparison, why important for interrelate reliability:


- validation
- establish reliability
- do different people look at the codes and apply them in the same way
- fidelity
- coders must have similar understanding of the context, question, hypotheses, insider knowledge,


thought experiment, direct comparisons between groups:


- we are studying high income and low income, what is poverty?
- high income says poverty is "low social status"
- low income says poverty is "managing bureaucracy of poverty"
- it's possible that you will find non-meaningful comparison because codes aren't well defined leading to a giant mess because neither group is talking about the same thing
